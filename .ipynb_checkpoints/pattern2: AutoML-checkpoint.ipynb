{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Install dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_aip:mbsdk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Google Cloud Notebook\n",
    "if os.path.exists(\"/opt/deeplearning/metadata/env_version\"):\n",
    "    USER_FLAG = \"--user\"\n",
    "else:\n",
    "    USER_FLAG = \"\"\n",
    "\n",
    "! pip3 install --upgrade google-cloud-aiplatform $USER_FLAG\n",
    "! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "! pip3 install $USER kfp google-cloud-pipeline-components --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Restart Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "restart"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_versions:kfp,gcpc"
   },
   "outputs": [],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Set Project, Region, Bucket, Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "autoset_project_id"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project ID: even-impulse-332807\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"[your-project-id]\"  # @param {type:\"string\"}\n",
    "if PROJECT_ID == \"\" or PROJECT_ID is None or PROJECT_ID == \"[your-project-id]\":\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = ! gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(\"Project ID:\", PROJECT_ID)\n",
    "    \n",
    "! gcloud config set project $PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "region"
   },
   "outputs": [],
   "source": [
    "REGION = \"us-central1\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "timestamp"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "autoset_bucket"
   },
   "outputs": [],
   "source": [
    "BUCKET_NAME = \"gs://[your-bucket-name]\"  # @param {type:\"string\"}\n",
    "if BUCKET_NAME == \"\" or BUCKET_NAME is None or BUCKET_NAME == \"gs://[your-bucket-name]\":\n",
    "    BUCKET_NAME = \"gs://\" + PROJECT_ID + \"aip-\" + TIMESTAMP\n",
    "! gsutil mb -l $REGION $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "create_bucket"
   },
   "source": [
    "**Only if your bucket doesn't already exist**: Run the following cell to create your Cloud Storage bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "validate_bucket"
   },
   "outputs": [],
   "source": [
    "! gsutil ls -al $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "autoset_service_account"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service Account: *       72552027929-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "SERVICE_ACCOUNT = \"[your-service-account]\"  # @param {type:\"string\"}\n",
    "if (\n",
    "    SERVICE_ACCOUNT == \"\"\n",
    "    or SERVICE_ACCOUNT is None\n",
    "    or SERVICE_ACCOUNT == \"[your-service-account]\"\n",
    "):\n",
    "    # Get your GCP project id from gcloud\n",
    "    shell_output = !gcloud auth list 2>/dev/null\n",
    "    SERVICE_ACCOUNT = shell_output[2].strip()\n",
    "    print(\"Service Account:\", SERVICE_ACCOUNT)\n",
    "    \n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectCreator $BUCKET_NAME\n",
    "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.objectViewer $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Instantiate client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "import_aip:mbsdk"
   },
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "import kfp\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "\n",
    "# API service endpoint\n",
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "PIPELINE_ROOT = \"{}/pipeline_root/flowers\".format(BUCKET_NAME)\n",
    "\n",
    "aip.init(project=PROJECT_ID, staging_bucket=BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "additional_imports"
   },
   "source": [
    "Additional imports."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "import_pipelines:min",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Define Domain Specific Language(DSL Pipeline definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "define_pipeline:gcpc,automl,flowers,icn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "@kfp.dsl.pipeline(name=\"automl-redbull-training\")\n",
    "def pipeline(project: str = PROJECT_ID, region: str = REGION):\n",
    "    \n",
    "    #https://google-cloud-pipeline-components.readthedocs.io/en/google-cloud-pipeline-components-0.1.6/google_cloud_pipeline_components.aiplatform.html\n",
    "    \n",
    "    # DataCreate component\n",
    "    ds_op = gcc_aip.ImageDatasetCreateOp(\n",
    "        project=project,\n",
    "        display_name=\"redbull\",\n",
    "        gcs_source=\"gs://filestore-dk/schema.csv\", # Table schema csv \n",
    "        import_schema_uri=aip.schema.dataset.ioformat.image.single_label_classification,\n",
    "    )\n",
    "    \n",
    "    # Training component\n",
    "    training_job_run_op = gcc_aip.AutoMLImageTrainingJobRunOp(\n",
    "        project=project,\n",
    "        display_name=\"train-automl-redbull\",\n",
    "        prediction_type=\"classification\",\n",
    "        model_type=\"CLOUD\",\n",
    "        base_model=None,\n",
    "        dataset=ds_op.outputs[\"dataset\"],\n",
    "        model_display_name=\"train-automl-redbull\",\n",
    "        training_fraction_split=0.6,\n",
    "        validation_fraction_split=0.2,\n",
    "        test_fraction_split=0.2,\n",
    "        budget_milli_node_hours=8000,\n",
    "    )\n",
    "    \n",
    "    # Endpoint component\n",
    "    endpoint_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project,\n",
    "        location=region,\n",
    "        display_name=\"train-automl-redbull\",\n",
    "    )\n",
    "    # Deploy component\n",
    "    gcc_aip.ModelDeployOp(\n",
    "        model=training_job_run_op.outputs[\"model\"],\n",
    "        endpoint=endpoint_op.outputs[\"endpoint\"],\n",
    "        automatic_resources_min_replica_count=1,\n",
    "        automatic_resources_max_replica_count=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Compile and run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "id": "compile_pipeline",
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"image classification pipeline.json\".replace(\" \", \"_\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run_pipeline:automl,image"
   },
   "outputs": [],
   "source": [
    "DISPLAY_NAME = \"flowers_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"image classification_pipeline.json\".replace(\" \", \"_\"),\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "! rm image_classification_pipeline.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view_pipeline_run:automl,image"
   },
   "source": [
    "Click on the generated link to see your run in the Cloud Console.\n",
    "\n",
    "<!-- It should look something like this as it is running:\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_tabular_classif.png\" width=\"40%\"/></a> -->\n",
    "\n",
    "In the UI, many of the pipeline DAG nodes will expand or collapse when you click on them. Here is a partially-expanded view of the DAG (click image to see larger version).\n",
    "\n",
    "<a href=\"https://storage.googleapis.com/amy-jo/images/mp/automl_image_classif.png\" target=\"_blank\"><img src=\"https://storage.googleapis.com/amy-jo/images/mp/automl_image_classif.png\" width=\"40%\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cleanup:pipelines",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cleaning up\n",
    "\n",
    "To clean up all Google Cloud resources used in this project, you can [delete the Google Cloud\n",
    "project](https://cloud.google.com/resource-manager/docs/creating-managing-projects#shutting_down_projects) you used for the tutorial.\n",
    "\n",
    "Otherwise, you can delete the individual resources you created in this tutorial -- *Note:* this is auto-generated and not all resources may be applicable for this tutorial:\n",
    "\n",
    "- Dataset\n",
    "- Pipeline\n",
    "- Model\n",
    "- Endpoint\n",
    "- Batch Job\n",
    "- Custom Job\n",
    "- Hyperparameter Tuning Job\n",
    "- Cloud Storage Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cleanup:pipelines"
   },
   "outputs": [],
   "source": [
    "delete_dataset = True\n",
    "delete_pipeline = True\n",
    "delete_model = True\n",
    "delete_endpoint = True\n",
    "delete_batchjob = True\n",
    "delete_customjob = True\n",
    "delete_hptjob = True\n",
    "delete_bucket = True\n",
    "\n",
    "try:\n",
    "    if delete_model and \"DISPLAY_NAME\" in globals():\n",
    "        models = aip.Model.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        model = models[0]\n",
    "        aip.Model.delete(model)\n",
    "        print(\"Deleted model:\", model)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    if delete_endpoint and \"DISPLAY_NAME\" in globals():\n",
    "        endpoints = aip.Endpoint.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}_endpoint\", order_by=\"create_time\"\n",
    "        )\n",
    "        endpoint = endpoints[0]\n",
    "        endpoint.undeploy_all()\n",
    "        aip.Endpoint.delete(endpoint.resource_name)\n",
    "        print(\"Deleted endpoint:\", endpoint)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_dataset and \"DISPLAY_NAME\" in globals():\n",
    "    if \"image\" == \"tabular\":\n",
    "        try:\n",
    "            datasets = aip.TabularDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TabularDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"image\" == \"image\":\n",
    "        try:\n",
    "            datasets = aip.ImageDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.ImageDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"image\" == \"text\":\n",
    "        try:\n",
    "            datasets = aip.TextDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TextDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"image\" == \"video\":\n",
    "        try:\n",
    "            datasets = aip.VideoDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.VideoDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "try:\n",
    "    if delete_pipeline and \"DISPLAY_NAME\" in globals():\n",
    "        pipelines = aip.PipelineJob.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        pipeline = pipelines[0]\n",
    "        aip.PipelineJob.delete(pipeline.resource_name)\n",
    "        print(\"Deleted pipeline:\", pipeline)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
    "    ! gsutil rm -r $BUCKET_NAME"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "google_cloud_pipeline_components_automl_images.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
